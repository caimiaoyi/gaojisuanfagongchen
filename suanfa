# gaojisuanfagongchen
# MEOMI算法
R：
library(minet)
library(Rgraphviz) 
library(sqldf)
library(igraph)
library(rlang)
library(dplyr)
library(pROC)
library(entropy)
library(modEvA)
library(parallel)
library(reshape)
library(ROCR)
library(readr)
library(tidyr)

# Read the data code in the folder
get_data_f <- function(path){
  # Read all files in the same directory
  fileNames <- dir(path) 
  filePath <- sapply(fileNames, function(x){ 
    paste(path,x,sep='/') })   
  data <- lapply(filePath, function(x){
    read.table(x,  header = FALSE, sep = "")})  
  return(data)
}
get_data_t <- function(path){
  fileNames <- dir(path) 
  filePath <- sapply(fileNames, function(x){ 
    paste(path,x,sep='/') })   
  data <- lapply(filePath, function(x){
    read.table(x,  header = TRUE, sep = "")})  
  return(data)
}
get_data_tab <- function(path){
  fileNames <- dir(path) 
  filePath <- sapply(fileNames, function(x){ 
    paste(path,x,sep='/') })   
  data <- lapply(filePath, function(x){
    read.table(x,  header = TRUE, sep = "\t")})  
  return(data)
}
## output file
put_data <- function(outPath, res, filename1){
  write.table(res, file = outPath, append = T, sep = ",", quote = F, row.names = F, col.names = F)
}

shrink <- function(mydata, lisan){
  
  mydata <- infotheo::discretize(mydata,"equalwidth", lisan)
  col <- ncol(mydata)
  row <- nrow(mydata)
  
  MI_J <- matrix(0, nr = col, nc = col)
  # Calculate the frequency by the column, because the column represents the gene
  for (m in 2:col) {
    for (n in 1:m) {
      b <- mydata[,c(n,m)]
      b[, 3] <- 1
      d <- aggregate(b[,3], by =  list(v1 = b[,1], v2 = b[,2]), FUN = "sum")
      colnames(d)<-c("v1","v2","v3")
      f <- spread(d,key = "v1", value = "v3", fill = 0)
      rownames(f)<-f[,1] #Take the first column of the data box as the row name
      f<-f[,-1]
      freq<-as.matrix(f)
      MI_J[m,n] <- entropy::mi.shrink(freq)
      MI_J[n,m] <- MI_J[m,n]
    }
  }

  res <- minet::clr(MI_J, skipDiagonal = 1)
  for (m in 2:col) {
    for (n in 1:m) {
      if(res[m,n]=="NaN")
      {
        res[m,n]=0
        res[n,m]=0
      }
    }
  }
  res <- res/max(res)
  colnames(res) <- colnames(mydata)
  rownames(res) <- colnames(mydata)
  return(res)
}


matrix.list <- function(res){
  ## Adjacency matrix transforms adjacency list and sorts
  result <- res
  b <- data.frame(v1 = 1:nrow(result)^2,v2 = 1:nrow(result)^2,value = 1:nrow(result)^2)
  for (i in 1:nrow(result)) {
    for (j in 1:ncol(result)) {
      ##Replace the possible default value NaN
      if(result[i,j]=="NaN"){result[i,j] <- 0}
      a <- c(row.names(result)[i],colnames(result)[j],result[i,j])
      b[(i-1)*nrow(result)+j,] <- a
      
    }
  }
  ##Sort by value
  or <- order(b[,3], decreasing = T)
  b <- b[or,]
  return(b)
}

## Adjacency list to matrix
list_to_matrix <- function(mydata,list){
  AMN <- matrix(0,nrow = ncol(mydata), ncol = ncol(mydata)) 
  colnames(AMN) <- colnames(mydata)
  row.names(AMN) <- colnames(mydata)
  list[,1:2]<-apply(list[,1:2],2,as.character) 
  colnames(list) <- c("V1","V2","V3")
  for (i in 1:nrow(list)) {
    AMN[list$V1[i],list$V2[i]] <- list$V3[i]
  }
  return(AMN)
}

##design conditions
canshu <- function(mydata, net1, my_prediction_end1){
  colnames(net1) <- c("V1","V2","V3")
  my_prediction_end <- my_prediction_end1[my_prediction_end1[,3]>0,1:2]
  true<-net1[net1$V3 == 1,1:2]
  options(max.print=1000000)

  all_possible<-as.data.frame(net1[,1:2])
  false<-sqldf('SELECT * FROM [all_possible] EXCEPT SELECT * FROM [true]')
  false1<-sqldf("SELECT * FROM [all_possible] EXCEPT SELECT * FROM [my_prediction_end]")
  tp<-sqldf('SELECT * FROM [true] InterSect SELECT * FROM [my_prediction_end]')
  fp<-sqldf('SELECT * FROM [false] InterSect SELECT * FROM [my_prediction_end]')
  tn<-sqldf('SELECT * FROM [false] InterSect SELECT * FROM [false1]')
  fn<-sqldf('SELECT * FROM [true] InterSect SELECT * FROM [false1]')
  PPV=nrow(tp)/(nrow(tp)+nrow(fp)) 
  TPR=nrow(tp)/(nrow(tp)+nrow(fn)) 
  afsbn_F=2*PPV*TPR/(PPV+TPR)  
  ACC = (nrow(tp)+nrow(tn))/(nrow(tp)+nrow(tn)+nrow(fp)+nrow(fn))
  MCC = (nrow(tp)*nrow(tn)-nrow(fp)*nrow(fn))/(sqrt((nrow(tp)+nrow(fp)))*sqrt((nrow(tp)+nrow(fn)))*sqrt((nrow(tn)+nrow(fp)))*sqrt((nrow(tn)+nrow(fn))))
  FPR = nrow(fp)/(nrow(fp)+nrow(tn))
  colnames(net1) <- c("v1","v2","label")
  colnames(my_prediction_end1) <- c("v1","v2","value")
  my <- full_join(net1, my_prediction_end1, by = c("v1","v2"))
  my[is.na(my)] <- 0 
  AUPR = AUC(obs=my$label,pred=my$value,curve = "PR", simplif=T, main = "PR curve")
  AUROC <- AUC(obs=my$label,pred=my$value,curve = "ROC", simplif=T, main = "ROC curve")

  r <- array(data = NA, dim = c(1, 12))
  colnames(r) <- c("tp","fp","tn","fn","TPR","PPV","afsbn_F","FPR","ACC","MCC","AUPR","AUROC")
  r[1,1] <- nrow(tp)
  r[1,2] <- nrow(fp)
  r[1,3] <- nrow(tn)
  r[1,4] <- nrow(fn)
  r[1,5] <- TPR
  r[1,6] <- PPV
  r[1,7] <- afsbn_F
  r[1,8] <- FPR
  r[1,9] <- ACC
  r[1,10] <- MCC
  r[1,11] <- AUPR
  r[1,12] <- AUROC
  return(r)
}
## Record the elapsed time
f <- function(start_time) {
  start_time <- as.POSIXct(start_time)
  dt <- difftime(Sys.time(), start_time, units="secs")
  # Since you only want the H:M:S, we can ignore the date...
  # but you have to be careful about time-zone issues
  format(.POSIXct(dt,tz="GMT"), "%H:%M:%S")
}

MEOMI <- function(mydata, net, bins, lamda, order){
  res1 <- minet(mydata,method = "clr", estimator = "mi.shrink", disc = "equalwidth",nbins = bins)
  res2 <- shrink(mydata,bins)
  b1 <- matrix.list(res1)
  b2 <- matrix.list(res2)
  #Replace the default value NaN
  for (j in 1:nrow(b1)) {
    if(b1[j,]$value=="NaN"){b1[j,]$value <- 0}
  }
  for (k in 1:nrow(b2)) {
    if(b2[k,]$value=="NaN"){b2[k,]$value <- 0}
  }
  my_prediction1 <- b1[b1[,3] > 0,] 
  my_prediction2 <- b2[b2[,3] > 0,] 
  my_prediction_end <- full_join(my_prediction1, my_prediction2, by = c("v1","v2"))
  my_prediction_end[is.na(my_prediction_end)] <- 0 
  my_prediction_end$v3 <- rowSums(as.data.frame(lapply(my_prediction_end[,3:4],as.numeric)))
  my_prediction_end$v3 <- my_prediction_end$v3/max(my_prediction_end$v3)            
  for (mm in 1:nrow(my_prediction_end)) {
    if(my_prediction_end[mm,3] !=0 & my_prediction_end[mm,4] != 0){
      my_prediction_end[mm,5]<-max(my_prediction_end[mm,3],my_prediction_end[mm,4])
    }
  }
  
  my_prediction_end1<-my_prediction_end[,c(1,2,5)]
  temp <- list_to_matrix(mydata, my_prediction_end1)
  original_data_new <- t(mydata)
  original_data_new <- as.data.frame(original_data_new)
  res_new <- CMI2(temp,original_data_new,lamda,order)
  colnames(res_new$Gval) <- colnames(temp)
  row.names(res_new$Gval) <- row.names(temp)
  Gval <- NULL
  for (ii in 1:nrow(res_new$G)) {
    for (jj in 1:ncol(res_new$G)) {
      if(ii!=jj){
        if(res_new$G[ii,jj]==1){
          Gval<- rbind(c(row.names(res_new$Gval)[ii],colnames(res_new$Gval)[jj],res_new$Gval[ii,jj]),Gval)
        }
      }
    }
  }
  Gval <- as.data.frame(Gval)
  or <- order(Gval[,3], decreasing = T)
  Gval <- Gval[or,]
  colnames(Gval)<- c("v1","v2","value")
  Gval[,3]<-as.data.frame(as.numeric(Gval$value)/max(as.numeric(Gval$value)))
  return(Gval)
}

CMI2 <- function(temp,data,lamda,order0) {
  n_gene <- nrow(data)
  G <- matrix(1,nrow=n_gene,ncol=n_gene)
  G[upper.tri(G, diag = TRUE)] = 0
  G <- G + t(G)
  Gval <- G
  order <- -1
  t <- 0

  while (t==0) {
  order <- order+1
  if(order0!=0){
    if(order>order0){
      break
    }
  }

  res <- edgereduce1(G,Gval,order,data,t,lamda,temp)
  G <- res$G
  Gval <- res$Gval
  t <- res$t
  if (t==0){
    print('No edge is reduce! Algorithm  finished!')
    break
    }else 
    t <- 0
  }
   order <- order-1
   res1 <- list(G=G,Gval=Gval,order=order)
   return(res1)
}

edgereduce1 <- function(G,Gval,order,data,t,lamda,temp) {
  val <- temp
  G0 <- G
  if(order==0){
    write.table(G, file = "D:/G0.csv", append = F, sep = ",", quote = F, row.names = F, col.names = F)
    write.table(Gval, file = "D:/Gval0.csv", append = F, sep = ",", quote = F, row.names = F, col.names = F)
    write.table(val, file = "D:/val0.csv", append = F, sep = ",", quote = F, row.names = F, col.names = F)
    G <- read.table("D:/G0.csv",header = F, sep = ",")
    Gval <- read.table("D:/Gval0.csv",header = F, sep = ",")
    val <- read.table("D:/val0.csv",header = F, sep = ",")
    for (ii in 2:nrow(G)) {
      for (jj in 1:ii) {
        if(G[ii,jj]!=0){
          cmiv<-val[ii,jj]
          Gval[ii,jj]<-cmiv
          Gval[jj,ii]<-cmiv
          if(cmiv<lamda){
            G[ii,jj]<-0
            G[jj,ii]<-0
          }
        }
      }
    }
    t=t+1
  }else{
     for (i in 2:nrow(G)) {
      for (j in 1:i) {
        if(G[i,j]!=0){
          adj <- NULL
          for (k in 1:nrow(G)) {
            if(G[i,k]==1 && G[j,k]==1){
              adj <- cbind(adj,k)
            }
          }  
         
         if(!is.null(adj)){
           if(ncol(adj)>=order){
            ## List all cases where transpose is required
            adj<-as.data.frame(adj)
            combntnslist <- t(combn(adj,order))
            combntnsrow <- nrow(combntnslist)
            cmiv <- 0
            v1 <- data[i,]
            v2 <- data[j,]
            for (k in 1:combntnsrow) {
              vcs <- data[as.numeric(combntnslist[k,]),]
              a <- MI2(v1,v2,vcs)
              cmiv <- max(cmiv,a)
            }
            Gval[i,j] <- cmiv
            Gval[j,i] <- cmiv
            if(cmiv<(lamda*combntnsrow)){
              G[i,j]<-0
              G[j,i]<-0
            }
            t <- t+1
          }}
        }
      }
    }
  }
res <- list(G=G,Gval=Gval,t = t)
return(res)
}

cmi <- function(v1,v2,vcs) {
  if(missing(vcs)){
    c1=det(cov(t(v1)))
    c2=det(cov(t(v2)))
    c3=det(cov(t(rbind(v1,v2))))
    cmiv=0.5*log(c1*c2/c3)
  }else{
    c1=det(cov(t(rbind(v1,vcs))))
    c2=det(cov(t(rbind(v2,vcs))))
    c3=det(cov(t(vcs)))
    c4=det(cov(t(rbind(v1,v2,vcs))))
    cmiv=0.5*log((c1*c2)/(c3*c4))   
  }
  if(is.infinite(cmiv)){
    cmiv=1.0e+010
  }
  return(cmiv)
}

MI2 <- function(x,y,z){
  r_dmi = (cas(x,y,z) + cas(y,x,z))/2

  return(r_dmi)
}

cas <- function(x,y,z){
  n1 <- nrow(z)
  n <- n1+2
  Cov <- cov(t(x))
  Covm <- cov(t(rbind(x,y,z)))
  Covm1 <- cov(t(rbind(x,z)))

  InvCov <- solve(Cov)
  InvCovm <- solve(Covm)
  InvCovm1 <- solve(Covm1)
  
  C11 <- InvCovm1[1,1]
  C12 <- 0
  C13 <- InvCovm1[1,2:(1+n1)]
  C23 <- InvCovm[2,3:(2+n1)]-InvCovm[1,2] * (1/(InvCovm[1,1]-InvCovm1[1,1]+InvCov[1,1])) * (InvCovm[1,3:(2+n1)] - InvCovm1[1,2:(1+n1)])
  C22 <- InvCovm[2,2]- InvCovm[1,2]^2 * (1/(InvCovm[1,1]-InvCovm1[1,1]+InvCov[1,1]))
  C112233 <- as.matrix(InvCovm[1,3:(2+n1)]-InvCovm1[1,2:(1+n1)])%*%t(as.matrix(InvCovm[1,3:(2+n1)]-InvCovm1[1,2:(1+n1)]))
  C2233 <- (1/(InvCovm[1,1]-InvCovm1[1,1]+InvCov[1,1])) * C112233
  C33 <- InvCovm[3:(2+n1),3:(2+n1)] - C2233
  InvC <- rbind(cbind(C11,C12,t(as.matrix(C13))),cbind(C12,C22,t(as.matrix(C23))),cbind((as.matrix(C13)),as.matrix(C23),C33))
  C0 <- Cov[1,1] * (InvCovm[1,1] - InvCovm1[1,1] + InvCov[1,1])
  CS <- 0.5 * (sum(diag(InvC%*%Covm))+log(C0)-n) 
  return(CS)
}



source("E:/R-4.3.0/bags/my_MEOMI_file/manipulation function.R")
  source("E:/R-4.3.0/bags/my_MEOMI_file/Conditional interaction information calculation.R")
  source("E:/R-4.3.0/bags/my_MEOMI_file/MEOMI.R")
  ##Set the path to read the file and the path to output the file
  path_data <- "E:/R-4.3.0/bags/my_MEOMI_file/Data_sets_and_standard_networks/size10/InSilicoSize10-Yeast3-null-mutants.tsv"
  path_standard <- "E:/R-4.3.0/bags/my_MEOMI_file/Data_sets_and_standard_networks/size10/DREAM3GoldStandard_InSilicoSize10_Yeast3.txt"
  Path_out <- "E:/R-4.3.0/bags/my_MEOMI_file/out_file/InSilicoSize10-Yeast3-null-mutants.csv" 
  ##Read standard network and data
  mydata <- read.table(file = path_data,header = T, sep = "\t")
  net <- read.table(file = path_standard,header = F, sep = "\t")
  ##Delete the extra rows
  if(colnames(mydata)[1] != "G1")
  {
    mydata<-mydata[-1,-1]
  } 
  ##The standard network is processed to change direction to undirection
  for(m in 1: nrow(net)){      
    if(net[m,]$V3==1){
      p <- net[m,]$V1
      q <- net[m,]$V2
      if(net[(net$V1==q&net$V2==p),]$V3 == 0){
        net[(net$V1==q&net$V2==p),]$V3 <- 1
      }
    }
  }
  ##Set up parameters
  lisan <- 5
  lambda <- 0.1
  order <- 4
  Gval<-MEOMI(mydata = mydata, net = net, bins = lisan,lamda = lambda, order = order)
  r <- canshu(mydata, net, Gval[,c(1:3)])
  put_data(Path_out, r, data[i])
  View(r)
# PCC算法
Python：
import argparse
import numpy as np
import csv 
import pandas as pd 
parser = argparse.ArgumentParser(description="Manual")
parser.add_argument("-k", type=float , default=1 , help="balance parameter")
parser.add_argument("-s", type=str , default="E:/R-4.3.0/bags/my_test_R/ECOLI10H/InSilicoSize10-Yeast3-null-mutants" , help="A path to the output 'sample weight' file")
parser.add_argument("-p", type=str, default="E:/R-4.3.0/bags/my_test_R/ECOLI10H/InSilicoSize10-Yeast3-null-mutants.txt", help="A path to the output ")  # output path  
args = parser.parse_args()
k , save , file = args.k , args.s , args.p
BLCA = pd.read_csv('E:/R-4.3.0/bags/my_MEOMI_file/Data_sets_and_standard_networks/size10/InSilicoSize10-Yeast3-null-mutants.tsv',sep='\t')
value_columns = BLCA.columns[1:]  # 获取除第一列外的其他列的索引  
pat = BLCA.iloc[:,0]  # 将列索引赋值给pat
gene = value_columns
patlen = len(pat)
value = BLCA.iloc[:,1:11]
value = value.T
genelen = len(gene)
value = np.corrcoef(value)
#'value' 和 'gene'  
value = np.corrcoef(value)  
with open(f"{save}.txt", mode='w') as wline:  
    wline.write("gene1\tgene2\traw_edge_score\n")  
    for g1, v1 in zip(gene, value):  
        wline.write('\n'.join(g1+'\t'+g2+'\t'+str(v2)  
                              for g2, v2 in zip(gene[1:], v1[1:])))  
        wline.write('\n')  
print("Finish")
weight = {}  
output_lines = []  
  
with open(file, mode='r') as rline:  
    _ = rline.readline()  # 跳过第一行  
    for nline in rline:  
        fields = nline.strip('\n').split('\t')  
        p, w = fields[0], float(fields[2])  # 我仍然需要p和w来进行权重检查  
          
        if w > 0:  # 只对权重大于0的行进行处理  
            weight.update({p: w})  
            output_lines.append(nline)  # 将整行添加到输出列表中  
  
# 将输出列表写入新的txt文件  
with open('E:/R-4.3.0/bags/my_test_R/ECOLI10H/InSilicoSize10-Yeast3-null-mutants1.txt', 'w') as output_file:  
    for line in output_lines:  
        output_file.write(line)  
  
del rline, nline, p, w, output_lines  
  
if not weight:  
    print("Warning! There is no sample with weight > 0 in the 'sample weight' file.")  
sys.exit()

R：
source("E:/R-4.3.0/bags/my_MEOMI_file/manipulation function.R")
source("E:/R-4.3.0/bags/my_MEOMI_file/Conditional interaction information calculation.R")
source("E:/R-4.3.0/bags/my_MEOMI_file/MEOMI.R")
path_data <- "E:/R-4.3.0/bags/my_MEOMI_file/Data_sets_and_standard_networks/size10/InSilicoSize10-Yeast3-null-mutants.tsv"
path_standard <- "E:/R-4.3.0/bags/my_MEOMI_file/Data_sets_and_standard_networks/size10/DREAM3GoldStandard_InSilicoSize10_Yeast3.txt"
Path_out <- "E:/R-4.3.0/bags/my_MEOMI_file/out_file/InSilicoSize10-Yeast3-null-mutants2.csv"
Gval_input <- "E:/R-4.3.0/bags/my_test_R/ECOLI10H/InSilicoSize10-Yeast3-null-mutants1.txt"
##Read standard network and data
mydata <- read.table(file = path_data,header = T, sep = "\t")
net <- read.table(file = path_standard,header = F, sep = "\t")
Gval<-read.table(file = Gval_input,header = F, sep = "\t")
r <- canshu(mydata, net, Gval[,c(1:3)])
put_data(Path_out, r, data[i])
View(r)
